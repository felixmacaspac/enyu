{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlkudcoiQFGz"
      },
      "source": [
        "### **Classification using sklearn and keras (with pandas)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">File access required:</font> In Colab this notebook requires first uploading files **Cities.csv**, **Players.csv**, and **Titanic.csv** using the *Files* feature in the left toolbar. If running the notebook on a local computer, simply ensure these files are in the same workspace as the notebook."
      ],
      "metadata": {
        "id": "I77EPVwDRJaO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "MSS0u6TNQFG1"
      },
      "outputs": [],
      "source": [
        "# Set-up\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from numpy.random import seed\n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxof3bb4QFG2"
      },
      "source": [
        "### Prepare Cities data for classification\n",
        "Predict <i>temperature category</i> from other features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "720BLLytQFG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f00669-3e7e-4795-9c19-40001841dfa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cold: 17\n",
            "cool: 92\n",
            "warm: 79\n",
            "hot: 25\n"
          ]
        }
      ],
      "source": [
        "# Read Cities.csv into dataframe, add column for temperature category\n",
        "# Note: For a dataframe D and integer i, D.loc[i] is the i-th row of D\n",
        "f = open('Cities.csv')\n",
        "cities = pd.read_csv(f)\n",
        "categories = []\n",
        "for i in range(len(cities)):\n",
        "    if cities.loc[i]['temperature'] < 5:\n",
        "        categories.append('cold')\n",
        "    elif cities.loc[i]['temperature'] < 9:\n",
        "        categories.append('cool')\n",
        "    elif cities.loc[i]['temperature'] < 15:\n",
        "        categories.append('warm')\n",
        "    else: categories.append('hot')\n",
        "cities['category'] = categories\n",
        "print(\"cold:\", len(cities[(cities.category == 'cold')]))\n",
        "print(\"cool:\", len(cities[(cities.category == 'cool')]))\n",
        "print(\"warm:\", len(cities[(cities.category == 'warm')]))\n",
        "print(\"hot:\", len(cities[(cities.category == 'hot')]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Tu_bmPoSQFG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd0db1a-f86d-40e9-9304-b56255f26031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set 181 items\n",
            "Test set 32 items\n"
          ]
        }
      ],
      "source": [
        "# Create training and test sets for cities data\n",
        "numitems = len(cities)\n",
        "percenttrain = 0.85\n",
        "numtrain = int(numitems*percenttrain)\n",
        "\n",
        "print('Training set', numtrain, 'items')\n",
        "print('Test set', numitems - numtrain, 'items')\n",
        "\n",
        "citiesTrain = cities[0:numtrain]\n",
        "citiesTest = cities[numtrain:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1Dr0WxgQFG4"
      },
      "source": [
        "### K-nearest-neighbors classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "xHDKqC1vQFG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dfd5bf0-d1f6-4f8c-b5f5-1c958c44d080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: warm  Actual: cool\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: hot  Actual: warm\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: cold  Actual: cool\n",
            "Predicted: cool  Actual: cool\n",
            "Predicted: cool  Actual: cool\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: cool  Actual: cold\n",
            "Predicted: cold  Actual: cold\n",
            "Predicted: cool  Actual: warm\n",
            "Predicted: cool  Actual: cold\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: cool  Actual: warm\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: hot  Actual: hot\n",
            "Predicted: cold  Actual: cold\n",
            "Predicted: cold  Actual: cold\n",
            "Predicted: cool  Actual: cold\n",
            "Predicted: hot  Actual: hot\n",
            "Predicted: warm  Actual: cool\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: cool  Actual: cool\n",
            "Predicted: cool  Actual: cool\n",
            "Predicted: cool  Actual: cool\n",
            "Predicted: cool  Actual: warm\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: cool  Actual: cool\n",
            "Predicted: warm  Actual: warm\n",
            "Predicted: cool  Actual: cool\n",
            "Accuracy: 0.6875\n"
          ]
        }
      ],
      "source": [
        "features = ['longitude', 'latitude']\n",
        "neighbors = 3\n",
        "predict = 'category'\n",
        "\n",
        "classifier = KNeighborsClassifier(neighbors)\n",
        "classifier.fit(citiesTrain[features], citiesTrain[predict])\n",
        "\n",
        "\n",
        "predictions = classifier.predict(citiesTest[features])\n",
        "\n",
        "# Calculate accuracy\n",
        "actuals = list(citiesTest[predict])\n",
        "correct = 0\n",
        "\n",
        "for i in range(len(actuals)):\n",
        "  print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))\n",
        "# Comment out print, try different values for neighbors, different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryRTSCCgQFG5"
      },
      "source": [
        "### <font color=\"green\">**Your Turn: K-nearest-neighbors on World Cup data**</font>\n",
        "<font color=\"green\">Predict <i>position</i> from one or more of <i>minutes, shots, passes, tackles, saves</i></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "77MKHzLtQFG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74c2b21-dc46-4f04-edaf-0eeb3a2196d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set 547 items\n",
            "Test set 48 items\n"
          ]
        }
      ],
      "source": [
        "# This cell does all the set-up, including reordering the data to avoid team bias.\n",
        "f = open('Players.csv')\n",
        "players = pd.read_csv(f)\n",
        "players = players.sort_values(by='surname')\n",
        "players = players.reset_index(drop=True)\n",
        "numitems = len(players)\n",
        "percenttrain = 0.92\n",
        "numtrain = int(numitems*percenttrain)\n",
        "print('Training set', numtrain, 'items')\n",
        "print('Test set', numitems - numtrain, 'items')\n",
        "playersTrain = players[0:numtrain]\n",
        "playersTest = players[numtrain:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "Qopw48z3QFG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02b9999-3456-4d89-917c-44902ad6b5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5625\n"
          ]
        }
      ],
      "source": [
        "# This cell does the classification.\n",
        "# Try different features and different numbers of neighbors.\n",
        "# What's the highest accuracy you can get?\n",
        "features = ['minutes', 'shots', 'passes', 'tackles', 'saves']\n",
        "neighbors = 8\n",
        "predict = 'position'\n",
        "classifier = KNeighborsClassifier(neighbors)\n",
        "classifier.fit(playersTrain[features], playersTrain[predict])\n",
        "predictions = classifier.predict(playersTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(playersTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "  # print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))\n",
        "# Comment out print, try different values for neighbors, different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAgMoPCsQFG6"
      },
      "source": [
        "### <font color=\"green\">**Your Turn Extra: K-nearest-neighbors on Titanic data - Graded**</font>\n",
        "<font color=\"green\">Predict <i>survived</i> from one or more of <i>gender, age, class, fare, embarked</i></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ssmntMEJQFG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f42742-462b-4959-a56b-313631d36e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set 819 items\n",
            "Test set 72 items\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-257007092.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic['gender'].replace({'M':0, 'F':1}, inplace=True)\n",
            "/tmp/ipython-input-257007092.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  titanic['gender'].replace({'M':0, 'F':1}, inplace=True)\n",
            "/tmp/ipython-input-257007092.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic['embarked'].replace({'Cherbourg':0, 'Southampton':1, 'Queenstown':2}, inplace=True)\n",
            "/tmp/ipython-input-257007092.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  titanic['embarked'].replace({'Cherbourg':0, 'Southampton':1, 'Queenstown':2}, inplace=True)\n",
            "/tmp/ipython-input-257007092.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic['age'].fillna(avg_age, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# This cell does all the set-up\n",
        "f = open('Titanic.csv')\n",
        "titanic = pd.read_csv(f)\n",
        "# Convert gender and embarked to numeric values and missing ages to average age\n",
        "titanic['gender'].replace({'M':0, 'F':1}, inplace=True)\n",
        "titanic['embarked'].replace({'Cherbourg':0, 'Southampton':1, 'Queenstown':2}, inplace=True)\n",
        "avg_age = np.average(titanic['age'].dropna().tolist())\n",
        "titanic['age'].fillna(avg_age, inplace=True)\n",
        "# Create training and test sets\n",
        "numitems = len(titanic)\n",
        "percenttrain = 0.92\n",
        "numtrain = int(numitems*percenttrain)\n",
        "print('Training set', numtrain, 'items')\n",
        "print('Test set', numitems - numtrain, 'items')\n",
        "titanicTrain = titanic[0:numtrain]\n",
        "titanicTest = titanic[numtrain:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "1QkwNrbWQFG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0055066e-b547-464d-e778-85cef6eb7bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.80556\n"
          ]
        }
      ],
      "source": [
        "# This cell does the classification.\n",
        "# Try different features and different numbers of neighbors.\n",
        "# What's the highest accuracy you can get?\n",
        "features = ['gender', 'age', 'class']\n",
        "neighbors = 8\n",
        "predict = 'survived'\n",
        "classifier = KNeighborsClassifier(neighbors)\n",
        "classifier.fit(titanicTrain[features], titanicTrain[predict])\n",
        "predictions = classifier.predict(titanicTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(titanicTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHUjWT6KQFG7"
      },
      "source": [
        "### Decision tree classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "A7X76CrJQFG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b071aab-1aa2-43c9-80f6-b80ce20b0322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.65625\n"
          ]
        }
      ],
      "source": [
        "features = ['longitude','latitude']\n",
        "split = 2\n",
        "predict = 'category'\n",
        "\n",
        "# random forest\n",
        "for x in range(1, 10):\n",
        "  dt = DecisionTreeClassifier(random_state=0, min_samples_split=split) # split parameter is optional\n",
        "  dt.fit(citiesTrain[features], citiesTrain[predict])\n",
        "\n",
        "  predictions = dt.predict(citiesTest[features])\n",
        "  # print(x ....)\n",
        "\n",
        "# aggregated predicted output\n",
        "\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "actuals = list(citiesTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))\n",
        "# Try different values for split, different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcYcgUoUQFG8"
      },
      "source": [
        "### \"Forest\" of decision trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "butlqjoPQFG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc1d3d6-3a42-425a-9a07-12c7e92cfe5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.78125\n"
          ]
        }
      ],
      "source": [
        "features = ['longitude', 'latitude']\n",
        "split = 10\n",
        "trees = 10\n",
        "predict = 'category'\n",
        "\n",
        "rf = RandomForestClassifier(random_state=0, min_samples_split=split, n_estimators=trees)\n",
        "rf.fit(citiesTrain[features], citiesTrain[predict])\n",
        "\n",
        "\n",
        "predictions = rf.predict(citiesTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(citiesTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))\n",
        "# Try different values for split and trees, different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwIO1eBuQFG9"
      },
      "source": [
        "### <font color=\"green\">**Your Turn: Decision tree and forest of trees on World Cup data - Graded**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "hAEWoJrnQFG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a69e7a-d19a-48ef-f728-456cdeb51bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6875\n"
          ]
        }
      ],
      "source": [
        "# SINGLE TREE\n",
        "# Try different features and different values for split.\n",
        "# What's the highest accuracy you can get?\n",
        "features = ['minutes', 'shots', 'passes', 'tackles', 'saves']\n",
        "split = 7\n",
        "predict = 'position'\n",
        "dt = DecisionTreeClassifier(random_state=0, min_samples_split=split, max_depth=10)\n",
        "dt.fit(playersTrain[features], playersTrain[predict])\n",
        "predictions = dt.predict(playersTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(playersTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "d8OY9PX2QFG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52821dae-9c2d-4ef6-b119-03d5709f4800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.70833\n"
          ]
        }
      ],
      "source": [
        "# FOREST OF TREES\n",
        "# Try different features and different values for split and trees.\n",
        "# What's the highest accuracy you can get?\n",
        "features = ['minutes', 'shots', 'passes', 'tackles', 'saves']\n",
        "split = 5\n",
        "trees = 50\n",
        "predict = 'position'\n",
        "rf = RandomForestClassifier(random_state=0, min_samples_split=split, n_estimators=trees, max_depth=10)\n",
        "rf.fit(playersTrain[features], playersTrain[predict])\n",
        "predictions = rf.predict(playersTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(playersTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_2L6LwCQFG-"
      },
      "source": [
        "### <font color=\"green\">**Your Turn Extra: Decision tree and forest of trees on Titanic data - Graded**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "2D_Hvqm6QFG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd878473-cdfc-47d2-c342-539581c0d2b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.79167\n"
          ]
        }
      ],
      "source": [
        "# SINGLE TREE\n",
        "# Try different features and different values for split.\n",
        "# What's the highest accuracy you can get?\n",
        "features = ['gender', 'age', 'class']\n",
        "split = 9\n",
        "predict = 'survived'\n",
        "dt = DecisionTreeClassifier(random_state=0, min_samples_split=split, max_depth=8) # parameter is optional\n",
        "dt.fit(titanicTrain[features], titanicTrain[predict])\n",
        "predictions = dt.predict(titanicTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(titanicTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "ooLoMxE3QFG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aafd7b83-21c4-4eb5-856f-f58540dce1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.79167\n"
          ]
        }
      ],
      "source": [
        "# FOREST OF TREES\n",
        "# Try different features and different values for split and trees.\n",
        "# What's the highest accuracy you can get?\n",
        "features = ['gender', 'age', 'class']\n",
        "split = 6\n",
        "trees = 10\n",
        "predict = 'survived'\n",
        "rf = RandomForestClassifier(random_state=0, min_samples_split=split, n_estimators=trees)\n",
        "rf.fit(titanicTrain[features], titanicTrain[predict])\n",
        "predictions = rf.predict(titanicTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(titanicTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dmN5JQIQFG_"
      },
      "source": [
        "### Naive Bayes classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "A8J8RFw_QFHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c914f16-781b-4a4c-90eb-19d2fca06cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.78125\n"
          ]
        }
      ],
      "source": [
        "features = ['longitude', 'latitude']\n",
        "predict = 'category'\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(citiesTrain[features], citiesTrain[predict])\n",
        "\n",
        "predictions = nb.predict(citiesTest[features])\n",
        "\n",
        "# Calculate accuracy\n",
        "actuals = list(citiesTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))\n",
        "# Try different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZYntlrAQFHA"
      },
      "source": [
        "### <font color=\"green\">**Your Turn: Naive Bayes on World Cup data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "umcLV_4rQFHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b5ad98-36b9-4f61-bbad-db7a6735dcb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6875\n"
          ]
        }
      ],
      "source": [
        "# Try different features. What's the highest accuracy you can get?\n",
        "features = ['minutes', 'shots', 'passes', 'tackles', 'saves']\n",
        "predict = 'position'\n",
        "nb = GaussianNB()\n",
        "nb.fit(playersTrain[features], playersTrain[predict])\n",
        "predictions = nb.predict(playersTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(playersTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BJzyGiTQFHA"
      },
      "source": [
        "### <font color=\"green\">**Your Turn Extra: Naive Bayes on Titanic data - Graded**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "QVm0cp10QFHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca45671-698e-4c8f-879b-e30db693b71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.76389\n"
          ]
        }
      ],
      "source": [
        "# Try different features. What's the highest accuracy you can get?\n",
        "features = ['gender', 'age', 'class', 'fare', 'embarked']\n",
        "predict = 'survived'\n",
        "nb = GaussianNB()\n",
        "nb.fit(titanicTrain[features], titanicTrain[predict])\n",
        "predictions = nb.predict(titanicTest[features])\n",
        "# Calculate accuracy\n",
        "actuals = list(titanicTest[predict])\n",
        "correct = 0\n",
        "for i in range(len(actuals)):\n",
        "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
        "  if predictions[i] == actuals[i]: correct +=1\n",
        "print('Accuracy:', round(correct/len(actuals),5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXDh563OQFHB"
      },
      "source": [
        "### Neural network classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "O5WX8b_GQFHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517b4409-cf2c-4d93-8f1c-08bb18d82432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 - 2s - 170ms/step - accuracy: 0.6133 - loss: 1.3135\n",
            "Epoch 2/10\n",
            "10/10 - 0s - 12ms/step - accuracy: 0.5580 - loss: 1.2323\n",
            "Epoch 3/10\n",
            "10/10 - 0s - 11ms/step - accuracy: 0.6188 - loss: 1.1596\n",
            "Epoch 4/10\n",
            "10/10 - 0s - 11ms/step - accuracy: 0.6575 - loss: 1.0892\n",
            "Epoch 5/10\n",
            "10/10 - 0s - 11ms/step - accuracy: 0.6630 - loss: 1.0206\n",
            "Epoch 6/10\n",
            "10/10 - 0s - 11ms/step - accuracy: 0.6740 - loss: 0.9556\n",
            "Epoch 7/10\n",
            "10/10 - 0s - 13ms/step - accuracy: 0.6906 - loss: 0.8969\n",
            "Epoch 8/10\n",
            "10/10 - 0s - 10ms/step - accuracy: 0.6906 - loss: 0.8448\n",
            "Epoch 9/10\n",
            "10/10 - 0s - 15ms/step - accuracy: 0.6906 - loss: 0.8012\n",
            "Epoch 10/10\n",
            "10/10 - 0s - 10ms/step - accuracy: 0.6906 - loss: 0.7611\n",
            "Number of epochs: 10\n",
            "Final accuracy on training data: 0.6906077265739441\n",
            "Accuracy on test data: 0.625\n"
          ]
        }
      ],
      "source": [
        "features = ['longitude', 'latitude']\n",
        "num_layers = 5 # including input and output, so must be >= 2\n",
        "num_epochs = 10 # number of iterations over training data\n",
        "batchsize = 20 # size of each batch during one iteration\n",
        "layer_outputs = 32 # dimensionality of output of each layer\n",
        "epoch_tracing = 'yes'\n",
        "predict = 'category'\n",
        "# Normalize feature values\n",
        "sc = StandardScaler()\n",
        "featurevals_train = sc.fit_transform(citiesTrain[features])\n",
        "featurevals_test = sc.fit_transform(citiesTest[features])\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(cities[predict])\n",
        "labels_train = encoder.transform(citiesTrain[predict])\n",
        "labels_test = encoder.transform(citiesTest[predict])\n",
        "# Set up neural-net classifier\n",
        "seed(1) # to eliminate some randomness\n",
        "tensorflow.random.set_seed(1) # to eliminate more randomness\n",
        "classifier = Sequential()\n",
        "# Input layer\n",
        "classifier.add(Dense(layer_outputs, activation='relu', input_dim=len(features)))\n",
        "\n",
        "# Hidden layers\n",
        "for i in range(num_layers-2):\n",
        "    classifier.add(Dense(layer_outputs, activation='relu',))\n",
        "\n",
        "\n",
        "# Output layer - first arg is number of labels, softmax for multi-class classification\n",
        "classifier.add(Dense(4, activation='softmax'))\n",
        "\n",
        "\n",
        "classifier.compile(optimizer ='adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "\n",
        "# Fit to training data\n",
        "if epoch_tracing == 'yes': v = 2\n",
        "else: v = 0\n",
        "hist = classifier.fit(featurevals_train, labels_train, batch_size=batchsize, epochs=num_epochs, verbose=v)\n",
        "print('Number of epochs:', num_epochs)\n",
        "print('Final accuracy on training data:', hist.history['accuracy'][-1])\n",
        "# Evaluate on test data\n",
        "test_acc = classifier.evaluate(featurevals_test, labels_test, verbose=0)[1]\n",
        "print('Accuracy on test data:', test_acc)\n",
        "# Try different values for num_layers, num_epochs, batch size, layer_outputs, and different features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W374RZM3QFHC"
      },
      "source": [
        "### <font color=\"green\">**Your Turn: Neural network on World Cup data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "g2sUnz0NQFHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f5ef9d-f68c-4e04-d5ca-88276e596189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of epochs: 30\n",
            "Final accuracy on training data: 0.6307129859924316\n",
            "Accuracy on test data: 0.6666666865348816\n"
          ]
        }
      ],
      "source": [
        "# Try different features and different values for num_layers, num_epochs,\n",
        "#  batch size, and layer_outputs.\n",
        "# What's the highest accuracy you can get?\n",
        "# Note: Although some randomness is removed by setting seeds in the code,\n",
        "#  you may still see somewhat different accuracy on different runs;\n",
        "#  changing the order of the features can also affect accuracy\n",
        "features = ['minutes', 'shots', 'tackles', 'saves']\n",
        "num_layers = 4 # including input and output, so must be >= 2\n",
        "num_epochs = 30 # number of iterations over training data\n",
        "batchsize = 32 # size of each batch during one iteration\n",
        "layer_outputs = 32 # dimensionality of output of each layer\n",
        "epoch_tracing = 'no'\n",
        "predict = 'position'\n",
        "# Normalize feature values\n",
        "sc = StandardScaler()\n",
        "featurevals_train = sc.fit_transform(playersTrain[features])\n",
        "featurevals_test = sc.fit_transform(playersTest[features])\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(players[predict])\n",
        "labels_train = encoder.transform(playersTrain[predict])\n",
        "labels_test = encoder.transform(playersTest[predict])\n",
        "# Set up neural-net classifier\n",
        "seed(1) # to eliminate some randomness\n",
        "tensorflow.random.set_seed(1) # to eliminate more randomness\n",
        "classifier = Sequential()\n",
        "# Input layer\n",
        "classifier.add(Dense(layer_outputs, activation='relu', input_dim=len(features)))\n",
        "# Hidden layers\n",
        "for i in range(num_layers-2):\n",
        "    classifier.add(Dense(layer_outputs, activation='relu',))\n",
        "# Output layer - first arg is number of labels, softmax for multi-class classification\n",
        "classifier.add(Dense(4, activation='softmax'))\n",
        "classifier.compile(optimizer ='adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "# Fit to training data\n",
        "if epoch_tracing == 'yes': v = 2\n",
        "else: v = 0\n",
        "hist = classifier.fit(featurevals_train, labels_train, batch_size=batchsize, epochs=num_epochs, verbose=v)\n",
        "print('Number of epochs:', num_epochs)\n",
        "print('Final accuracy on training data:', hist.history['accuracy'][-1])\n",
        "# Evaluate on test data\n",
        "test_acc = classifier.evaluate(featurevals_test, labels_test, verbose=0)[1]\n",
        "print('Accuracy on test data:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEKxlWPxQFHC"
      },
      "source": [
        "### <font color=\"green\">**Your Turn Extra: Neural network on Titanic data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "0KYHOL58QFHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ad16af-8051-4f72-e460-b8814dcda250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of epochs: 50\n",
            "Final accuracy on training data: 0.8021978139877319\n",
            "Accuracy on test data: 0.8194444179534912\n"
          ]
        }
      ],
      "source": [
        "# Try different features and different values for num_layers, num_epochs,\n",
        "#  batch size, and layer_outputs.\n",
        "# What's the highest accuracy you can get?\n",
        "# Note: Although some randomness is removed by setting seeds in the code,\n",
        "#  you may still see somewhat different accuracy on different runs;\n",
        "#  changing the order of the features can also affect accuracy\n",
        "features = ['gender', 'age', 'class']\n",
        "num_layers = 4 # including input and output, so must be >= 2\n",
        "num_epochs = 50 # number of iterations over training data\n",
        "batchsize = 16 # size of each batch during one iteration\n",
        "layer_outputs = 32 # dimensionality of output of each layer\n",
        "epoch_tracing = 'no'\n",
        "predict = 'survived'\n",
        "# Normalize feature values\n",
        "sc = StandardScaler()\n",
        "featurevals_train = sc.fit_transform(titanicTrain[features])\n",
        "featurevals_test = sc.fit_transform(titanicTest[features])\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(titanic[predict])\n",
        "labels_train = encoder.transform(titanicTrain[predict])\n",
        "labels_test = encoder.transform(titanicTest[predict])\n",
        "# Set up neural-net classifier\n",
        "seed(1) # to eliminate some randomness\n",
        "tensorflow.random.set_seed(1) # to eliminate more randomness\n",
        "classifier = Sequential()\n",
        "# Input layer\n",
        "classifier.add(Dense(layer_outputs, activation='relu', input_dim=len(features)))\n",
        "# Hidden layers\n",
        "for i in range(num_layers-2):\n",
        "    classifier.add(Dense(layer_outputs, activation='relu',))\n",
        "# Output layer - first arg is number of labels, softmax for multi-class classification\n",
        "classifier.add(Dense(4, activation='softmax'))\n",
        "classifier.compile(optimizer ='adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "# Fit to training data\n",
        "if epoch_tracing == 'yes': v = 2\n",
        "else: v = 0\n",
        "hist = classifier.fit(featurevals_train, labels_train, batch_size=batchsize, epochs=num_epochs, verbose=v)\n",
        "print('Number of epochs:', num_epochs)\n",
        "print('Final accuracy on training data:', hist.history['accuracy'][-1])\n",
        "# Evaluate on test data\n",
        "test_acc = classifier.evaluate(featurevals_test, labels_test, verbose=0)[1]\n",
        "print('Accuracy on test data:', test_acc)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}